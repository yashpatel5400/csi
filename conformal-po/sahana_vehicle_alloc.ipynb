{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srayan/miniconda3/envs/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rsome import ro \n",
    "import rsome as rso                           # import the ro module\n",
    "from rsome import grb_solver as grb\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sbibm\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the setup for vehicle pre-allocation problem but it looks like they have some \n",
    "# wait and see decisions to make.  I'm not sure how to handle that.  I'm going to try \n",
    "# (the last two sentences are from github copilot! Wild!)\n",
    "I, J = 1, 10\n",
    "r = np.array([4.50, 4.41, 3.61, 4.49, 4.38, 4.58, 4.53, 4.64, 4.58, 4.32])\n",
    "c = 3 * np.ones((I, J))\n",
    "q = 400 * np.ones(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest path problem or minimum cost flow problem\n",
    "# min_{x} max_{c in U(c)} c^Tx\n",
    "# Constraints x[i, j]\n",
    "\n",
    "# Creating the edge list so that one can only travel south or west\n",
    "\n",
    "edges = np.zeros((25, 25))\n",
    "edge_list = {}\n",
    "adjacency_list = {i : [[], []] for i in range(25)}\n",
    "grid_size = 5\n",
    "vertex_count = 25\n",
    "\n",
    "edge_index = 0\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        if i <(grid_size -1) and j < (grid_size -1):\n",
    "            # East edge\n",
    "            edges[i * 5 + j, i * 5 + j + 1] = 1\n",
    "            # edge_list[edge_index] = (i * 5 + j, i * 5 + j + 1)\n",
    "            edge_list[(i * 5 + j, i * 5 + j + 1)] = edge_index\n",
    "            edge_index += 1\n",
    "            adjacency_list[i * 5 + j][0].append(i * 5 + j + 1)\n",
    "            adjacency_list[i * 5 + j + 1][1].append(i * 5 + j)\n",
    "\n",
    "            # South edge\n",
    "            edges[i * 5 + j, (i + 1) * 5 + j] = 1\n",
    "            # edge_list[edge_index] = (i * 5 + j, (i + 1) * 5 + j)\n",
    "            edge_list[(i * 5 + j, (i + 1) * 5 + j)] = edge_index\n",
    "            edge_index += 1\n",
    "            adjacency_list[i * 5 + j][0].append((i + 1) * 5 + j)\n",
    "            adjacency_list[(i + 1) * 5 + j][1].append(i * 5 + j)\n",
    "        elif i== (grid_size -1) and j < (grid_size -1):\n",
    "            # East edge\n",
    "            edges[i * 5 + j, i * 5 + j + 1] = 1\n",
    "            # edge_list[edge_index] = (i * 5 + j, i * 5 + j + 1)\n",
    "            edge_list[(i * 5 + j, i * 5 + j + 1)] = edge_index\n",
    "            edge_index += 1\n",
    "            adjacency_list[i * 5 + j][0].append(i * 5 + j + 1)\n",
    "            adjacency_list[i * 5 + j + 1][1].append(i * 5 + j)\n",
    "\n",
    "        elif i < (grid_size -1) and j == (grid_size -1):\n",
    "            # South edge\n",
    "            edges[i * 5 + j, (i + 1) * 5 + j] = 1\n",
    "            # edge_list[edge_index] = (i * 5 + j, (i + 1) * 5 + j)\n",
    "            edge_list[(i * 5 + j, (i + 1) * 5 + j)] = edge_index\n",
    "            edge_index += 1\n",
    "            adjacency_list[i * 5 + j][0].append((i + 1) * 5 + j)\n",
    "            adjacency_list[(i + 1) * 5 + j][1].append(i * 5 + j)\n",
    "edge_count = int(edges.sum())\n",
    "rev_edge_list = {v : k for k, v in edge_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, d, Theta, edge_count):\n",
    "    # Generating zs\n",
    "    z = np.random.normal(0, 1, (N, d))\n",
    "\n",
    "    # Computing cost with some noise\n",
    "    cost_wo_noise = ((1/d)**(0.5) * np.matmul(z, Theta.T) + 3)**5 + 1\n",
    "    noise = np.random.uniform(low = 0.75, high = 1.25, size = (N, edge_count))\n",
    "    cost = cost_wo_noise * noise\n",
    "    return z, cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation for training and calibration\n",
    "# generating the theta such that some of the covariates are independent of cost\n",
    "np.random.seed(0)\n",
    "d = 10\n",
    "Theta = np.random.binomial(1, 0.5, (edge_count, d))\n",
    "irrelevant_zs = np.random.choice(range(d), size = 2)\n",
    "Theta[:, irrelevant_zs] = 0\n",
    "N_train = 1000\n",
    "z_train, cost_train = generate_data(N_train, d, Theta, edge_count)\n",
    "N_calib = 500\n",
    "z_calib, cost_calib = generate_data(N_calib, d, Theta, edge_count)\n",
    "N_test = 1000\n",
    "z_test, c_test = generate_data(N_test, d, Theta, edge_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset for the model\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_tensor = lambda r : torch.tensor(r).to(torch.float32).to(device)\n",
    "z_train, z_cal = to_tensor(z_train), to_tensor(z_calib)\n",
    "c_train, c_cal = to_tensor(cost_train), to_tensor(cost_calib)\n",
    "z_test, c_test = to_tensor(z_test), to_tensor(c_test)\n",
    "train_dataset = TensorDataset(z_train, c_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        order_dict = []\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            order_dict.append(('Linear Layer {}'.format(i), nn.Linear(hidden_sizes[i], hidden_sizes[i+1])))\n",
    "            if i < len(hidden_sizes) - 2:\n",
    "                order_dict.append(('BatchNorm Layer {}'.format(i), nn.BatchNorm1d(hidden_sizes[i+1])))\n",
    "                order_dict.append(('ReLU Layer {}'.format(i), nn.ReLU()))\n",
    "        self.mlp = nn.Sequential(OrderedDict(order_dict))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 264677.8750\n",
      "Epoch [101/1000], Loss: 104702.0703\n",
      "Epoch [201/1000], Loss: 57920.2383\n",
      "Epoch [301/1000], Loss: 45233.1445\n",
      "Epoch [401/1000], Loss: 27315.7480\n",
      "Epoch [501/1000], Loss: 86438.4219\n",
      "Epoch [601/1000], Loss: 42735.6562\n",
      "Epoch [701/1000], Loss: 15530.2734\n",
      "Epoch [801/1000], Loss: 13807.7217\n",
      "Epoch [901/1000], Loss: 12944.4492\n"
     ]
    }
   ],
   "source": [
    "model = MLP([d, 64, 128, 64, edge_count]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1_000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept_model_train(c_train):\n",
    "    return c_train.mean(0)\n",
    "\n",
    "marg_model = intercept_model_train(c_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_score_quantile(alpha, model, c_calib, isCond = False, z_calib = None):\n",
    "    if not isCond:\n",
    "        preds = model\n",
    "    else:\n",
    "        model.eval()\n",
    "        preds = model(z_calib)\n",
    "    with torch.no_grad():\n",
    "        losses = np.linalg.norm((preds - c_calib).detach().cpu().numpy(), np.inf, axis=1) \n",
    "        N_c = c_calib.shape[0]\n",
    "        return np.quantile(losses, (N_c + 1)*(1 - alpha)/N_c) #, np.sort(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipsoid_score_quantile(alpha, model, c_calib, isCond= False, z_calib = None):\n",
    "    if not isCond:\n",
    "        preds = model\n",
    "    else:\n",
    "        model.eval()\n",
    "        preds = model(z_calib)\n",
    "    with torch.no_grad():\n",
    "        residuals = (preds - c_calib).detach().cpu().numpy()\n",
    "        cov = np.cov(residuals.T)\n",
    "        N_c = c_calib.shape[0]\n",
    "        calib_scores = np.sqrt(np.einsum('ni ,ij, jn -> n', residuals, np.linalg.inv(cov), residuals.T))\n",
    "        return np.quantile(calib_scores, (N_c + 1)*(1 - alpha)/N_c), cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diamond_score_quantile(alpha, model, c_calib, isCond= False, z_calib = None):\n",
    "    if not isCond:\n",
    "        preds = model\n",
    "    else:\n",
    "        model.eval()\n",
    "        preds = model(z_calib)\n",
    "    with torch.no_grad():\n",
    "        losses = np.linalg.norm((preds - c_calib).detach().cpu().numpy(), ord=1, axis=1) \n",
    "        N_c = c_calib.shape[0]\n",
    "        return np.quantile(losses, (N_c + 1)*(1 - alpha)/N_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = box_score_quantile(0.05, model, c_cal, True, z_cal)\n",
    "score_marg = box_score_quantile(0.05, marg_model, c_cal)\n",
    "score_elip, cov_elip = ellipsoid_score_quantile(0.05, model, c_cal, True, z_cal)\n",
    "score_elip_marg, cov_elip_marg = ellipsoid_score_quantile(0.05, marg_model, c_cal)\n",
    "score_diam = diamond_score_quantile(0.05, model, c_cal, True, z_cal)\n",
    "score_diam_marg = diamond_score_quantile(0.05, marg_model, c_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cost_matrix(cost_vector, edges, vector_count):\n",
    "    cost_matrix = np.zeros((vector_count, vector_count))\n",
    "    cost_index = 0\n",
    "    for i in range(vector_count):\n",
    "        for j in range(vector_count):\n",
    "            if edges[i, j] == 1:\n",
    "                cost_matrix[i, j] = cost_vector[cost_index]\n",
    "                cost_index += 1\n",
    "            else:\n",
    "                cost_matrix[i, j] = 1000000\n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_uq_solve(model, edge_list, adjacency_list, z0, vertex_count, edge_count):\n",
    "    c_pred = model(z0)\n",
    "    c_pred = c_pred.detach().cpu().numpy().reshape(-1)\n",
    "    # c_pred = fill_cost_matrix(c_pred, edges, vertex_count)\n",
    "\n",
    "    model = ro.Model()\n",
    "    w = model.dvar(edge_count, 'B')\n",
    "    model.min((c_pred*w).sum())\n",
    "    model.st(w[0] + w[1] == 1)\n",
    "    model.st(w[-1] + w[-6] == 1)\n",
    "    for j in range(1, vertex_count - 1):\n",
    "        outgoing_edges = [(j, i) for i in adjacency_list[j][0]]\n",
    "        incoming_edges = [(i, j) for i in adjacency_list[j][1]]\n",
    "        model.st(w[[edge_list.get(x) for x in outgoing_edges]].sum() - w[[edge_list.get(x) for x in incoming_edges]].sum() == 0)\n",
    "    model.solve(grb)\n",
    "    return model.get(), w.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditonal/marginal box solve\n",
    "def box_solve_RO(model, CP_score, edge_list, adjacency_list, vertex_count, edge_count, c_true, isCond = False, z0 = None):\n",
    "\n",
    "    # Checking if the model is conditional or marginal\n",
    "    if not isCond:\n",
    "        c_pred = model.detach().cpu().numpy().reshape(-1)\n",
    "    else:\n",
    "        c_pred = model(z0)\n",
    "        c_pred = c_pred.detach().cpu().numpy().reshape(-1)\n",
    "    \n",
    "    # Computing the lower and upper bounds for the Uncertainty set\n",
    "    c_lb = c_pred - CP_score\n",
    "    c_ub = c_pred + CP_score\n",
    "\n",
    "    # Checking if the true cost is in the uncertainty set\n",
    "    truth = c_true.detach().cpu().numpy().reshape(-1)\n",
    "    covered = (truth >= c_lb).all() and (truth <= c_ub).all()\n",
    "\n",
    "    # Initializing the model, decision variables and random variables\n",
    "    model = ro.Model()\n",
    "    w = model.dvar(edge_count, 'B')\n",
    "    c = model.rvar(edge_count)\n",
    "    uset = (c_lb <= c, c <= c_ub)\n",
    "\n",
    "    # Adding the objective and constraints\n",
    "    model.minmax((c*w).sum(), uset)\n",
    "    model.st(w[0] + w[1] == 1)\n",
    "    model.st(w[-1] + w[-6] == 1)\n",
    "    for j in range(1, vertex_count - 1):\n",
    "        outgoing_edges = [(j, i) for i in adjacency_list[j][0]]\n",
    "        incoming_edges = [(i, j) for i in adjacency_list[j][1]]\n",
    "        model.st(w[[edge_list.get(x) for x in outgoing_edges]].sum() - w[[edge_list.get(x) for x in incoming_edges]].sum() == 0)\n",
    "    model.solve(grb)\n",
    "    return model.get(), w.get(), covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional/marginal ellipsoid solve\n",
    "def ellipsoid_solve_RO(model, CP_score, cov,  edge_list, adjacency_list,  vertex_count, edge_count, c_true, isCond = False, z0 = None):\n",
    "    # Checking if the model is conditional or marginal\n",
    "    if not isCond:\n",
    "        c_pred = model.detach().cpu().numpy().reshape(-1)\n",
    "    else:\n",
    "        c_pred = model(z0)\n",
    "        c_pred = c_pred.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "     # Checking if the true cost is in the uncertainty set\n",
    "    truth = c_true.detach().cpu().numpy().reshape(-1)\n",
    "    cholesky_sqrt = np.linalg.cholesky(np.linalg.inv(cov))\n",
    "    covered = (np.linalg.norm((truth - c_pred) @ cholesky_sqrt) <= CP_score)\n",
    "\n",
    "    # Initializing the model, decision variables and random variables\n",
    "    model = ro.Model()\n",
    "    w = model.dvar(edge_count, 'B')\n",
    "    c = model.rvar(edge_count)\n",
    "    uset = rso.norm((c - c_pred).T @ cholesky_sqrt) <= CP_score\n",
    "    print(uset)\n",
    "\n",
    "    # Adding the objective and constraints\n",
    "    model.minmax((c*w).sum(), uset)\n",
    "    model.st(w[0] + w[1] == 1)\n",
    "    model.st(w[-1] + w[-6] == 1) # specific to 5 by 5 grid\n",
    "    for j in range(1, vertex_count - 1):\n",
    "        outgoing_edges = [(j, i) for i in adjacency_list[j][0]]\n",
    "        incoming_edges = [(i, j) for i in adjacency_list[j][1]]\n",
    "        model.st(w[[edge_list.get(x) for x in outgoing_edges]].sum() - w[[edge_list.get(x) for x in incoming_edges]].sum() == 0)\n",
    "    \n",
    "\n",
    "    # Solving the model\n",
    "    model.solve(grb)\n",
    "    return model.get(), w.get(), covered\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditonal/marginal diamond solve\n",
    "def diamond_solve_RO(model, CP_score, edge_list, adjacency_list, vertex_count, edge_count, c_true, isCond = False, z0 = None):\n",
    "\n",
    "    # Checking if the model is conditional or marginal\n",
    "    if not isCond:\n",
    "        c_pred = model.detach().cpu().numpy().reshape(-1)\n",
    "    else:\n",
    "        c_pred = model(z0)\n",
    "        c_pred = c_pred.detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "    # Checking if the true cost is in the uncertainty set\n",
    "    truth = c_true.detach().cpu().numpy().reshape(-1)\n",
    "    covered = (np.linalg.norm(truth - c_pred, ord = 1)<= CP_score)\n",
    "\n",
    "    # Initializing the model, decision variables and random variables\n",
    "    model = ro.Model()\n",
    "    w = model.dvar(edge_count, 'B')\n",
    "    c = model.rvar(edge_count)\n",
    "    uset = rso.norm((c - c_pred), degree = 1) <= CP_score\n",
    "\n",
    "    # Adding the objective and constraints\n",
    "    model.minmax((c*w).sum(), uset)\n",
    "    model.st(w[0] + w[1] == 1)\n",
    "    model.st(w[-1] + w[-6] == 1)\n",
    "    for j in range(1, vertex_count - 1):\n",
    "        outgoing_edges = [(j, i) for i in adjacency_list[j][0]]\n",
    "        incoming_edges = [(i, j) for i in adjacency_list[j][1]]\n",
    "        model.st(w[[edge_list.get(x) for x in outgoing_edges]].sum() - w[[edge_list.get(x) for x in incoming_edges]].sum() == 0)\n",
    "    model.solve(grb)\n",
    "    return model.get(), w.get(), covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0009s\n",
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0009s\n"
     ]
    }
   ],
   "source": [
    "obj_ro, w_ro, covered = box_solve_RO(model, score, edge_list, adjacency_list, 25, 40, c_test[0], True, z_test[0, :].reshape(1, -1))\n",
    "obj_ro_marg, w_ro_marg, covered_marg = box_solve_RO(marg_model, score_marg, edge_list, adjacency_list, 25, 40, c_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 convex constraint\n",
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.2252s\n",
      "1 convex constraint\n",
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0564s\n"
     ]
    }
   ],
   "source": [
    "obj_ro_ellip, w_ro_ellip, covered_ellip = ellipsoid_solve_RO(model, score_elip, cov_elip, edge_list, adjacency_list,  25, 40, c_test[0], True, z_test[0, :].reshape(1, -1))\n",
    "obj_ro_ellip_marg, w_ro_ellip_marg, covered_ellip_marg = ellipsoid_solve_RO(marg_model, score_marg, cov_elip_marg, edge_list, adjacency_list,  25, 40, c_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0018s\n",
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0013s\n"
     ]
    }
   ],
   "source": [
    "obj_ro_dia, w_ro_dia, covered_dia = diamond_solve_RO(model, score_diam, edge_list, adjacency_list, 25, 40, c_test[0], True, z_test[0, :].reshape(1, -1))\n",
    "obj_ro_dia_marg, w_ro_dia_marg, covered_dia_marg = diamond_solve_RO(marg_model, score_diam_marg, edge_list, adjacency_list, 25, 40, c_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2024-10-28\n",
      "Being solved by Gurobi...\n",
      "Solution status: 2\n",
      "Running time: 0.0010s\n"
     ]
    }
   ],
   "source": [
    "obj, w = no_uq_solve(model, edge_list, adjacency_list, z_test[0, :].reshape(1, -1), 25, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model(z_test[0, :].reshape(1, -1)))\n",
    "print(covered)\n",
    "print(obj)\n",
    "print(np.where(w == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (0, 1), 1: (0, 5), 2: (1, 2), 3: (1, 6), 4: (2, 3), 5: (2, 7), 6: (3, 4), 7: (3, 8), 8: (4, 9), 9: (5, 6), 10: (5, 10), 11: (6, 7), 12: (6, 11), 13: (7, 8), 14: (7, 12), 15: (8, 9), 16: (8, 13), 17: (9, 14), 18: (10, 11), 19: (10, 15), 20: (11, 12), 21: (11, 16), 22: (12, 13), 23: (12, 17), 24: (13, 14), 25: (13, 18), 26: (14, 19), 27: (15, 16), 28: (15, 20), 29: (16, 17), 30: (16, 21), 31: (17, 18), 32: (17, 22), 33: (18, 19), 34: (18, 23), 35: (19, 24), 36: (20, 21), 37: (21, 22), 38: (22, 23), 39: (23, 24)}\n",
      "[ 0  3 11 14 23 32 38 39]\n",
      "6462.946044921875\n",
      "True\n",
      "[ 1  9 12 20 23 32 38 39]\n",
      "21248.157470703125\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(rev_edge_list)\n",
    "print(np.argwhere(w_ro == 1).reshape(-1))\n",
    "print(obj_ro)\n",
    "print(covered)\n",
    "\n",
    "print(np.argwhere(w_ro_marg == 1).reshape(-1))\n",
    "print(obj_ro_marg)\n",
    "print(covered_marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4561.2061394798275\n",
      "True\n",
      "[ 1  9 12 20 23 32 38 39]\n",
      "4015714.5448763384\n",
      "True\n",
      "[ 1  9 12 20 23 32 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(obj_ro_ellip)\n",
    "print(covered_ellip)\n",
    "print(np.argwhere(w_ro_ellip == 1).reshape(-1))\n",
    "\n",
    "print(obj_ro_ellip_marg)\n",
    "print(covered_ellip_marg)\n",
    "print(np.argwhere(w_ro_ellip_marg == 1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (0, 1), 1: (0, 5), 2: (1, 2), 3: (1, 6), 4: (2, 3), 5: (2, 7), 6: (3, 4), 7: (3, 8), 8: (4, 9), 9: (5, 6), 10: (5, 10), 11: (6, 7), 12: (6, 11), 13: (7, 8), 14: (7, 12), 15: (8, 9), 16: (8, 13), 17: (9, 14), 18: (10, 11), 19: (10, 15), 20: (11, 12), 21: (11, 16), 22: (12, 13), 23: (12, 17), 24: (13, 14), 25: (13, 18), 26: (14, 19), 27: (15, 16), 28: (15, 20), 29: (16, 17), 30: (16, 21), 31: (17, 18), 32: (17, 22), 33: (18, 19), 34: (18, 23), 35: (19, 24), 36: (20, 21), 37: (21, 22), 38: (22, 23), 39: (23, 24)}\n",
      "6761.48194529724\n",
      "True\n",
      "[ 0  3 11 14 23 32 38 39]\n",
      "24708.191504101556\n",
      "True\n",
      "[ 1  9 12 20 23 32 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(rev_edge_list)\n",
    "print(obj_ro_dia)\n",
    "print(covered_dia)\n",
    "print(np.argwhere(w_ro_dia == 1).reshape(-1))\n",
    "\n",
    "print(obj_ro_dia_marg)\n",
    "print(covered_dia_marg)\n",
    "print(np.argwhere(w_ro_dia_marg == 1).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
