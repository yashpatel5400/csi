{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rsome import ro                            # import the ro module\n",
    "from rsome import grb_solver as grb\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the setup for vehicle pre-allocation problem but it looks like they have some \n",
    "# wait and see decisions to make.  I'm not sure how to handle that.  I'm going to try \n",
    "# (the last two sentences are from github copilot! Wild!)\n",
    "I, J = 1, 10\n",
    "r = np.array([4.50, 4.41, 3.61, 4.49, 4.38, 4.58, 4.53, 4.64, 4.58, 4.32])\n",
    "c = 3 * np.ones((I, J))\n",
    "q = 400 * np.ones(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest path problem or minimum cost flow problem\n",
    "# min_{x} max_{c in U(c)} c^Tx\n",
    "# Constraints x[i, j]\n",
    "\n",
    "# Creating the edge list so that one can only travel south or west\n",
    "\n",
    "edges = np.zeros((25, 25))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i <4 and j < 4:\n",
    "            edges[i * 5 + j, i * 5 + j + 1] = 1\n",
    "            edges[i * 5 + j, (i + 1) * 5 + j] = 1\n",
    "        elif i== 4 and j < 4:\n",
    "            edges[i * 5 + j, i * 5 + j + 1] = 1\n",
    "        elif i < 4 and j == 4:\n",
    "            edges[i * 5 + j, (i + 1) * 5 + j] = 1\n",
    "edge_count = int(edges.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the theta such that some of the covariates are independent of cost\n",
    "np.random.seed(0)\n",
    "d = 10\n",
    "Theta = np.random.binomial(1, 0.5, (edge_count, d))\n",
    "irrelevant_zs = np.random.choice(range(d), size = 2)\n",
    "Theta[:, irrelevant_zs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, d, Theta):\n",
    "    # Generating zs\n",
    "    z = np.random.normal(0, 1, (N, d))\n",
    "\n",
    "    # Computing cost with some noise\n",
    "    cost_wo_noise = ((1/d)**(0.5) * np.matmul(z, Theta.T) + 3)**5 + 1\n",
    "    noise = np.random.uniform(low = 0.75, high = 1.25, size = (N, edge_count))\n",
    "    cost = cost_wo_noise * noise\n",
    "    return z, cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation for training and calibration\n",
    "N_train = 1000\n",
    "z_train, cost_train = generate_data(N_train, d, Theta)\n",
    "N_calib = 500\n",
    "z_calib, cost_calib = generate_data(N_calib, d, Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srayan/miniconda3/envs/genIP/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset for the model\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "to_tensor = lambda r : torch.tensor(r).to(torch.float32).to(device)\n",
    "z_train, z_cal = to_tensor(z_train), to_tensor(z_calib)\n",
    "c_train, c_cal = to_tensor(cost_train), to_tensor(cost_calib)\n",
    "train_dataset = TensorDataset(z_train, c_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        order_dict = []\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            order_dict.append(('Linear Layer {}'.format(i), nn.Linear(hidden_sizes[i], hidden_sizes[i+1])))\n",
    "            if i < len(hidden_sizes) - 2:\n",
    "                order_dict.append(('BatchNorm Layer {}'.format(i), nn.BatchNorm1d(hidden_sizes[i+1])))\n",
    "                order_dict.append(('ReLU Layer {}'.format(i), nn.ReLU()))\n",
    "        self.mlp = nn.Sequential(OrderedDict(order_dict))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 301862.2812\n",
      "Epoch [101/1000], Loss: 129071.9375\n",
      "Epoch [201/1000], Loss: 71389.2812\n",
      "Epoch [301/1000], Loss: 74906.1016\n",
      "Epoch [401/1000], Loss: 43061.4609\n",
      "Epoch [501/1000], Loss: 17194.7734\n",
      "Epoch [601/1000], Loss: 20102.0742\n",
      "Epoch [701/1000], Loss: 22190.7969\n",
      "Epoch [801/1000], Loss: 32013.7324\n",
      "Epoch [901/1000], Loss: 10827.7305\n"
     ]
    }
   ],
   "source": [
    "model = MLP([d, 64, 128, 64, edge_count]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 1_000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_score_quantile(alpha, model, z_calib, c_calib):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = np.linalg.norm((model(z_calib) - c_calib).detach().cpu().numpy(), np.inf, axis=1) \n",
    "        N_c = z_calib.shape[0]\n",
    "        return np.quantile(losses, (N_c + 1)*(1 - alpha)/N_c) #, np.sort(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_solve_RO(model, CP_score, edges, z0, edge_count, vertex_count):\n",
    "    c_pred = model(z0)\n",
    "    c_pred = c_pred.detach().cpu().numpy()\n",
    "\n",
    "    model = ro.Model()\n",
    "\n",
    "    w = model.dvar((vertex_count, vertex_count) 'B')\n",
    "    c = model.rvar((vertex_count, vertex_count))\n",
    "    uset = (ro.norm(c[i], np.inf) <= CP_score)\n",
    "\n",
    "    model.minmax(c @ w, uset)\n",
    "    model.st(w <= 1)\n",
    "    model.st(w >= 0)\n",
    "    model.st(p @ w <= B)\n",
    "\n",
    "    model.solve(grb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
